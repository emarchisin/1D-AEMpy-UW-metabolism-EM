{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get resources\n",
    "'''\n",
    "import sys\n",
    "sys.path.insert(1,\"/Users/admin/Desktop/jasmine/lakes21_parquet/Eco_KGML_workshop\")   #change path to local file\n",
    "\n",
    "import os\n",
    "if os.path.exists(\"/Users/admin/Desktop/jasmine/lakes21_parquet/Eco_KGML_workshop\"):\n",
    "  print(\"Directory already exists.\")\n",
    "else:\n",
    "  os.system(\"git clone https://github.com/jasminehyu/Machine_Learning_Model_for_Predicting_Dissolved_Oxygen_in_Lakes.git\")\n",
    "  print(\"Repository cloned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89187940",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import necessary modules\n",
    "'''\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from utils import  run_all, Utils\n",
    "from encoder_decoder import seq2seq\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set up environment - Running on GPU if available\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    print('Computational device:GPU')\n",
    "\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under Runtime -> \"\n",
    "        \"Change runtime type. select GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set up environment - Handles variabilty and remain reproducible by controlling sources of randomness through setting seed values\"\n",
    "'''\n",
    "seed = 2025\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define some hyperparameters required for learning\n",
    "'''\n",
    "#Type of the model\n",
    "model_type='LSTM'\n",
    "\n",
    "#Output size of our encoder_decoder model(Number of target variable)\n",
    "output_size=1\n",
    "\n",
    "#Number of layers in our deep learning model\n",
    "num_layer=1\n",
    "\n",
    "#Hidden cell size\n",
    "hidden_feature_size=64\n",
    "\n",
    "#Dropout is a form of regularization\n",
    "dropout = 0.05\n",
    "\n",
    "#Whether we want to shuffle the batches while generating the training batches\n",
    "batch_shuffle = True\n",
    "\n",
    "#Frequency of evaluation --> if iteration_num % eval_freq ==0 --> then perform evaluation\n",
    "eval_freq = 1 \n",
    "\n",
    "'''\n",
    "Learning rate scheduler parameters\n",
    "'''\n",
    "max_lr=5e-4\n",
    "div_factor=100\n",
    "pct_start=0.05\n",
    "anneal_strategy='cos'\n",
    "final_div_factor=10000.0\n",
    "\n",
    "'''\n",
    "Parameters for early stopping\n",
    "'''\n",
    "early_stop = False\n",
    "#If there is no imrovement for a 'thres' number of epochs, stop the training process\n",
    "thres=5\n",
    "#Quantifying the improvement. If the loss is greater than min_val_loss_so_far + delta for thres number of iterations, stop the training\n",
    "delta=0.5\n",
    "#Specifying the percentage of times we want to enforce teacher forcing\n",
    "teacher_forcing_ratio = 0.0\n",
    "training_prediction = 'recursive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58020f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read the file with Lake Mendota's data\n",
    "'''\n",
    "file_name='lake_me_year.csv'\n",
    "me_df=pd.read_csv(file_name)\n",
    "me_df_training=me_df[(me_df['year']==2019) | (me_df['year']==2020)]\n",
    "me_df_testing\n",
    "'''\n",
    "An Adjustment on datetimes that include time at 12:00 am\n",
    "'''\n",
    "def add_missing_time(datetime):\n",
    "    if len(datetime)==10:\n",
    "        return datetime+ ' 00:00:00'\n",
    "    return datetime\n",
    "\n",
    "me_df_training['datetime']=me_df_training['datetime'].apply(add_missing_time)\n",
    "me_df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Filter specific columns from me_df for training and testing\n",
    "'''\n",
    "me_df_training=me_df_training.loc[:,[\"datetime\",\"date\",\"time\",\"do\",\"temp\",\"tp\",\"tn\",\"do_lf\",\"secchi\"]]\n",
    "me_df_testing=me_df_testing.loc[:,[\"datetime\",\"date\",\"time\",\"do\",\"temp\",\"tp\",\"tn\",\"do_lf\",\"secchi\"]]\n",
    "me_df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1464f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define columns(features, date, target) for learning\n",
    "'''\n",
    "feature_cols=['temp','tp','tn','do_lf','secchi']\n",
    "date_col=['datetime','date','time']\n",
    "target_col=['do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c812b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a utility object\n",
    "'''\n",
    "utils = Utils(num_features=len(feature_cols), inp_cols=feature_cols, target_cols=target_col, date_col=date_col, num_out_features=output_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7944f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split train/test data(either by ratio or time)\n",
    "'''\n",
    "split_ratio=0.6\n",
    "df_train,df_val=utils.train_test_split(me_df_training,split_ratio=split_ratio)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d80a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalize the data\n",
    "'''\n",
    "df_train=utils.normalize(df_train)\n",
    "df_val=utils.normalize(df_val,use_stat=True)\n",
    "df_test=utils.normalize(me_df_testing,use_stat=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71040f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generating data sample\n",
    "'''\n",
    "#Lookback window\n",
    "input_window=14\n",
    "#Horizon window=1(for predicting the present value?!)\n",
    "output_window=7\n",
    "#Define the number of stride the sliding window need to take  while creating each sample(lookback window + horizon window= 1 sample)\n",
    "stride=1\n",
    "\n",
    "#Create samples: 1 sample = lookback window + horizon window\n",
    "x_train,y_train=utils.windowed_dataset(df_train,input_window,output_window,stride)\n",
    "x_val,y_val=utils.windowed_dataset(df_val,input_window,output_window,stride)\n",
    "x_test,y_test=utils.windowed_dataset(df_test,input_window,output_window,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4023aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Modeling - Define hyperparameters for model training\n",
    "'''\n",
    "#Batch size during training\n",
    "batch_size=32\n",
    "\n",
    "#Number of epochs(1 epoch = 1 pass of the complete training data through the model)\n",
    "epochs=100\n",
    "\n",
    "#Learning rate specifies the rate where we want to update the model parameters after every training pass\n",
    "learning_rate=0.0001\n",
    "\n",
    "#Specify the amount of L2 regularization to be applied\n",
    "weight_decay=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define config file\n",
    "'''\n",
    "config={\n",
    "    \"batch_size\":batch_size,\n",
    "    \"epochs\":epochs,\n",
    "    \"learning_rate\":learning_rate,\n",
    "    \"eval_freq\":eval_freq,\n",
    "    \"batch_shuffle\":batch_shuffle,\n",
    "    \"dropout\":dropout,\n",
    "    \"num_layers\":num_layer,\n",
    "    \"hidden_feature_size\":hidden_feature_size,\n",
    "    \"model_type\":model_type,\n",
    "    \"teacher_forcing_ratio\":teacher_forcing_ratio,\n",
    "    \"max_lr\":max_lr,\n",
    "    \"div_factor\":div_factor,\n",
    "    \"pct_start\":pct_start,\n",
    "    \"anneal_strategy\":anneal_strategy,\n",
    "    \"final_div_factor\":final_div_factor,\n",
    "    \"dataset\":file_name,\n",
    "    \"split_ratio\":split_ratio,\n",
    "    \"input_window\":input_window,\n",
    "    \"output_window\":output_window,\n",
    "    \"early_stop_thres\":thres,\n",
    "    \"early_stop_delta\":delta,\n",
    "    \"early_stop\":early_stop,\n",
    "    \"weight_decay\":weight_decay\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b12227",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create the seq2seq model\n",
    "'''\n",
    "model=seq2seq(input_size=x_train.shape[2],\n",
    "              hidden_size=hidden_feature_size,\n",
    "              output_size=output_size,\n",
    "              model_type=model_type,\n",
    "              num_layers=num_layer,\n",
    "              utils=utils,\n",
    "              dropout=dropout,\n",
    "              device=device\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01612005",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train the model\n",
    "'''\n",
    "loss,val_rmse,train_rmse=model.train_model(x_train,y_train,x_val,y_val,\n",
    "                                            target_len=output_window,\n",
    "                                            config=config,\n",
    "                                            training_prediction=training_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c23c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot train-val Root Mean Squared Error(RMSE)\n",
    "'''\n",
    "utils.plot_RMSE_epochs(val_rmse,train_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e593942",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluation - Perform Evaluation\n",
    "'''\n",
    "train_eval_metrics=model.evaluate_batch(x_train.to(device),y_train.to(device))\n",
    "val_eval_metrics=model.evaluate_batch(x_val.to(device),y_val.to(device))\n",
    "test_eval_metrics=model.evaluate_batch(x_test.to(device),y_test.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization - Generate the plots on test data\n",
    "'''\n",
    "horizon_range=[1]  #Specify the list of T+n predictions to plot\n",
    "plot_df_test=utils.plot_predictions(df_test,test_eval_metrics,horizon_range,split='Test') \n",
    "# this will plot T+1 predictions and Ground Observed Dissolved Oxygen and create a dataset(Timeline as label and T+1 predictions as one column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56064d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the tag (Timeline) to a column and rename it\n",
    "'''\n",
    "plot_df_test=plot_df_test.reset_index()\n",
    "plot_df_test.rename(columns={'index':'datetime'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Merge plot_df_test(the dataset with predictions) with actual observations\n",
    "'''\n",
    "merged_df_test=pd.merge(plot_df_test,me_df,on='datetime',how='left')\n",
    "merged_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the model\n",
    "'''\n",
    "MODEL_PATH_SAVE = \"./current_model_weights\"\n",
    "torch.save(model.state_dict(), MODEL_PATH_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609ffa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
